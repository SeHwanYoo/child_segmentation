{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import string\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'strides', 'se_ratio', 'final_bn'\n",
    "])\n",
    "\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
    "              expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25, \n",
    "              final_bn=True),\n",
    "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25, \n",
    "              final_bn=True),\n",
    "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25, \n",
    "              final_bn=True),\n",
    "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25,\n",
    "              final_bn=True),\n",
    "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25,\n",
    "              final_bn=True),\n",
    "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25,\n",
    "              final_bn=True),\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
    "              expand_ratio=6, id_skip=False, strides=[1, 1], se_ratio=0.25,\n",
    "              final_bn=False)\n",
    "    \n",
    "]\n",
    "\n",
    "ENCODER_LAYERS = [ 'block2a', 'block3a', 'block4a',  'block6a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(Layer):\n",
    "    \"\"\"Implementation of Squeeze and Excitation network\"\"\"\n",
    "    def __init__(self, name, filters, ratio, kernel_initializer, \n",
    "                    activation=tf.nn.swish):\n",
    "        super(SEBlock, self).__init__(name)\n",
    "\n",
    "        self.squeeze = GlobalAveragePooling2D(name='se_squeeze')\n",
    "        self.reduce = Conv2D(filters * ratio, \n",
    "                             kernel_size=1,\n",
    "                             activation=activation, \n",
    "                             padding='same',\n",
    "                             use_bias=True,\n",
    "                             kernel_initializer=kernel_initializer,\n",
    "                             name='se_reduce')\n",
    "\n",
    "        self.expand = Conv2D(filters, \n",
    "                                kernel_size=1,\n",
    "                                activation='sigmoid',\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                name='se_expand')\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.squeeze(input)\n",
    "        channels = x.shape[-1]\n",
    "        x = tf.reshape(x, (-1, 1, 1, channels))\n",
    "        x = self.reduce(x)\n",
    "        x = self.expand(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConvBlock(Layer):\n",
    "    def __init__(self, block_args, kernel_initializer, drop_rate=None, \n",
    "                 name='', activation=tf.nn.swish):\n",
    "        super(MBConvBlock, self).__init__(name=name)\n",
    "        filters = block_args.input_filters * block_args.expand_ratio\n",
    "        self.block_args = block_args\n",
    "        if block_args.expand_ratio != 1:\n",
    "            self.expand_conv = Conv2D(filters, 1, padding='same', \n",
    "                                        use_bias=False,\n",
    "                                        kernel_initializer=kernel_initializer,\n",
    "                                        name='expand_cov')\n",
    "            self.expand_bn = BatchNormalization(axis=3, name='expand_bn')\n",
    "            self.expand_act = Activation(activation, name='expand_activation')\n",
    "\n",
    "        self.depth_conv = DepthwiseConv2D(block_args.kernel_size,\n",
    "                              strides=block_args.strides,\n",
    "                              padding='same',\n",
    "                              use_bias=False,\n",
    "                              depthwise_initializer=kernel_initializer,\n",
    "                              name='dwconv')\n",
    "        self.depth_bn = BatchNormalization(axis=3, name='bn')\n",
    "        self.depth_act = Activation(activation, name='activation')\n",
    "\n",
    "        if block_args.se_ratio > 0:\n",
    "            self.se_block = SEBlock('se', filters , block_args.se_ratio, \n",
    "                                    kernel_initializer)\n",
    "\n",
    "        self.out_conv = Conv2D(block_args.output_filters, 1, \n",
    "                                padding='same',\n",
    "                                use_bias=False,\n",
    "                                kernel_initializer=kernel_initializer,\n",
    "                                name='project')\n",
    "        \n",
    "        self.out_bn =  BatchNormalization(axis=3, name='project_bn')\n",
    "\n",
    "    def call(self, input, training):\n",
    "        x = input\n",
    "        if self.block_args.expand_ratio != 1:\n",
    "            x = self.expand_conv(x)\n",
    "            x = self.expand_bn(x)\n",
    "            x = self.expand_act(x)\n",
    "            enc = x\n",
    "\n",
    "        x = self.depth_conv(x)\n",
    "        x = self.depth_bn(x)\n",
    "        x = self.depth_act(x)\n",
    "\n",
    "        if self.block_args.se_ratio > 0:\n",
    "            se = self.se_block(x)\n",
    "            x = tf.math.multiply(x, se)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "        if self.block_args.final_bn:\n",
    "          x = self.out_bn(x)\n",
    "\n",
    "        if self.block_args.id_skip and self.block_args.input_filters == self.block_args.output_filters:\n",
    "            x = tf.math.add(x, input)\n",
    "\n",
    "        return x, enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(Layer):\n",
    "    \"\"\"Implementation of base Efficient net\"\"\"\n",
    "    def __init__(self, width_coefficient, \n",
    "                 depth_coefficient, \n",
    "                 dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2,\n",
    "                 depth_divisor=8,\n",
    "                 activation=tf.nn.swish,\n",
    "                 blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "                 encoder_layers=ENCODER_LAYERS,\n",
    "                 layer_name='efficient_net',\n",
    "                 weights='imagenet'):\n",
    "      \n",
    "      super(EfficientNet, self).__init__(layer_name)\n",
    "      self.layer_name = layer_name\n",
    "      self.block_args = blocks_args\n",
    "      self.encoder_layers = encoder_layers\n",
    "      \n",
    "      #stem \n",
    "      self.stem_conv = Conv2D(self.round_filters(32, width_coefficient, depth_divisor), 3,\n",
    "                              strides=(2,2),\n",
    "                              padding='same',\n",
    "                              use_bias=False,\n",
    "                              kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                              name='stem_conv')\n",
    "      self.stem_bn = BatchNormalization(axis=3, name='stem_bn')\n",
    "      self.stem_act = Activation(activation, name='stem_Activation')\n",
    "\n",
    "      self.mb_blocks = {}\n",
    "      for idx, block_args in enumerate(blocks_args):\n",
    "          block_args = block_args._replace(\n",
    "              input_filters=self.round_filters(block_args.input_filters,\n",
    "                                      width_coefficient, depth_divisor),\n",
    "              output_filters=self.round_filters(block_args.output_filters,\n",
    "                                        width_coefficient, depth_divisor),\n",
    "              num_repeat=self.round_repeats(block_args.num_repeat, depth_coefficient))\n",
    "          self.mb_blocks.update({f'block{idx + 1}a' : \n",
    "                              MBConvBlock(block_args, CONV_KERNEL_INITIALIZER ,\n",
    "                                  drop_rate=None, name=f'block{idx + 1}a')})\n",
    "          if idx < (len(blocks_args) - 1):\n",
    "            for bidx in range((block_args.num_repeat - 1)):\n",
    "                block_prefix = f'block{idx + 1}{string.ascii_lowercase[bidx + 1]}'\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, \n",
    "                                                  strides=[1, 1])\n",
    "                self.mb_blocks.update({block_prefix : MBConvBlock(block_args, \n",
    "                                            CONV_KERNEL_INITIALIZER,\n",
    "                                            drop_rate=None, name=block_prefix)})\n",
    "              \n",
    "\n",
    "\n",
    "    def call(self, input, training=True):\n",
    "      self.output_layers = []\n",
    "      x = self.stem_conv(input)\n",
    "      x = self.stem_bn(x)\n",
    "      x = self.stem_act(x) # 64 * 64\n",
    "\n",
    "      for key in self.mb_blocks.keys():\n",
    "        block = self.mb_blocks[key] \n",
    "        x, enc = block(x, training) \n",
    "        if key in self.encoder_layers:\n",
    "          self.output_layers.append(enc) # 64, 32, 16, 8, 4\n",
    "\n",
    "      self.output_layers.append(x)\n",
    "      return self.output_layers\n",
    "\n",
    "    def get_config(self):\n",
    "      return {'layer_name': self.layer_name}\n",
    "\n",
    "\n",
    "    def round_filters(self, filters, width_coefficient, \n",
    "                            depth_divisor):\n",
    "      \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
    "      filters *= width_coefficient\n",
    "      new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "      new_filters = max(depth_divisor, new_filters)\n",
    "      # Make sure that round down does not go down by more than 10%.\n",
    "      if new_filters < 0.9 * filters:\n",
    "          new_filters += depth_divisor\n",
    "      return int(new_filters)\n",
    "\n",
    "    def round_repeats(self, repeats, depth_coefficient):\n",
    "      return int(math.ceil(depth_coefficient * repeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(Layer):\n",
    "    def __init__(self, filters1, filters2, name, kernel_size=3):\n",
    "      super(DecoderBlock, self).__init__(name=name)\n",
    "\n",
    "      self.conv_1 = Conv2D(filters1, kernel_size=1, name='conv_1')\n",
    "      self.bn_1 = BatchNormalization(name='conv_bn_1')\n",
    "      self.act_1 = Activation('relu', name='conv_relu_1')\n",
    "\n",
    "      self.up = Conv2DTranspose(filters1, kernel_size, \n",
    "                      strides=(2, 2), padding='same', name='up')\n",
    "      self.up_bn = BatchNormalization(name='up_bn')\n",
    "      self.up_relu = Activation('relu', name='up_act')\n",
    "\n",
    "      self.conv_2 = Conv2D(filters2, kernel_size=1, name='conv_2')\n",
    "      self.bn_2 = BatchNormalization(name='conv_bn_2')\n",
    "      self.act_2 = Activation('relu', name='conv_relu_2')\n",
    "\n",
    "\n",
    "    def call(self, input):\n",
    "      x = self.conv_1(input)\n",
    "      x = self.bn_1(x)\n",
    "      x = self.act_1(x)\n",
    "\n",
    "      x = self.up(x)\n",
    "      x = self.up_bn(x)\n",
    "      x = self.up_relu(x)\n",
    "\n",
    "      x = self.conv_2(x)\n",
    "      x = self.bn_2(x)\n",
    "      x = self.act_2(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "    def __init__(self, start_filters, name='decoder'):\n",
    "      super(Decoder, self).__init__(name)\n",
    "      name = name\n",
    "\n",
    "      self.decoder4 = DecoderBlock(start_filters * 32, \n",
    "                                      start_filters * 16, name='decoder4', kernel_size=3)\n",
    "      self.decoder3 = DecoderBlock(start_filters * 16, \n",
    "                                      start_filters * 8, name='decoder3', kernel_size=3)\n",
    "      self.decoder2 = DecoderBlock(start_filters * 8, \n",
    "                                      start_filters * 4, name='decoder2', kernel_size=3)\n",
    "      self.decoder1 = DecoderBlock(start_filters * 4, \n",
    "                                      start_filters * 2, name='decoder1', kernel_size=3)\n",
    "\n",
    "\n",
    "    def call(self, encoder):\n",
    "      #e0 - 64, e1 - 32, e2 - 16, e3 - 8, e4 - 4\n",
    "      em, e4, e3, e2, e1 = encoder\n",
    "\n",
    "\n",
    "      d4 = self.decoder4(em) # 8 -> 16\n",
    "      d4 = tf.concat([d4, e4], axis=-1)\n",
    "\n",
    "      \n",
    "      d3 = self.decoder3(d4) # 16 -> 32\n",
    "      d3 = tf.concat([d3, e3], axis=-1)\n",
    "\n",
    "      d2 = self.decoder2(d3) # 32 -> 64\n",
    "      d2 = tf.concat([d2, e2], axis=-1)\n",
    "\n",
    "      d1 = self.decoder1(d2) # 64 -> 128\n",
    "      d1 = tf.concat([d1, e1], axis=-1)\n",
    "      \n",
    "      return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(Model):\n",
    "    def __init__(self, name, width_coefficient=1, depth_coefficient=1, num_classes=2):\n",
    "        super(UNet, self).__init__(name=name)\n",
    "        # self.name = name \n",
    "        start_filters = 16\n",
    "        self.backbone = EfficientNet(width_coefficient=width_coefficient, \n",
    "                                     depth_coefficient=depth_coefficient)\n",
    "        \n",
    "        self.middle_conv = Conv2D(start_filters * 32, kernel_size=3, \n",
    "                                    padding='same', name='middle_conv')\n",
    "        self.middle_bn = BatchNormalization(axis=3, name='middle_bn')\n",
    "        self.middle_act = Activation('relu', name='middle_activation')\n",
    "\n",
    "        self.decoder = Decoder(start_filters)\n",
    "\n",
    "        self.out_conv = Conv2DTranspose(num_classes, 3, strides=2,\n",
    "                            padding='same', name='out_conv') \n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self, input, training):\n",
    "        encoders = self.backbone(input)\n",
    "        e1, e2, e3, e4, e5 = encoders \n",
    "\n",
    "        # #middle block\n",
    "        em = self.middle_conv(e5)\n",
    "        em = self.middle_bn(em)\n",
    "        em = self.middle_act(em) \n",
    "\n",
    "        encoders = [em, e4, e3, e2, e1]\n",
    "        mask = self.decoder(encoders)\n",
    "\n",
    "        mask = self.out_conv(mask)\n",
    "    \n",
    "        return mask\n",
    "\n",
    "\n",
    "    def compile(self, optimizer, loss_fn, train_loss, test_loss,\n",
    "                    metric):\n",
    "      super(UNet, self).compile(optimizer, metrics=metric)\n",
    "      self.optimizer = optimizer \n",
    "      self.loss_fn = loss_fn\n",
    "\n",
    "      self.train_loss = train_loss\n",
    "      self.test_loss = test_loss\n",
    "\n",
    "  \n",
    "    def train_step(self, data):\n",
    "        images, mask = data \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(images, training=True)\n",
    "            loss = self.loss_fn(mask, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.train_loss(loss)\n",
    "        self.compiled_metrics.update_state(mask, predictions)\n",
    "        mean_iou = self.metrics[0]\n",
    "\n",
    "        return {'loss': self.train_loss.result(), \\\n",
    "                    mean_iou.name: mean_iou.result()}\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "        images, mask = data \n",
    "\n",
    "        predictions = self(images, training=False)\n",
    "        loss = self.loss_fn(mask, predictions)\n",
    "\n",
    "        self.test_loss(loss)\n",
    "        self.compiled_metrics.update_state(mask, predictions)\n",
    "        mean_iou = self.metrics[0]\n",
    "\n",
    "        return {'loss': self.test_loss.result(), \\\n",
    "                    mean_iou.name: mean_iou.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_train(files_name):\n",
    "  input_images = [] \n",
    "  input_masks = []\n",
    "  for file_name in files_name:\n",
    "    input_image = tf.io.read_file(file_name)\n",
    "    input_image = tf.io.decode_jpeg(input_image, channels=3)\n",
    "    input_image = tf.image.resize(input_image, (128, 128))\n",
    "      \n",
    "    file_name = file_name[:-4] + '.png'\n",
    "    \n",
    "    if os.path.isfile(file_name) == False:\n",
    "        print(f'Not found mask file : {file_name}') \n",
    "        none_mask += 1\n",
    "        continue\n",
    "      \n",
    "    input_mask = tf.io.read_file(file_name)\n",
    "    input_mask = tf.io.decode_jpeg(input_mask, channels=3)\n",
    "    input_mask = tf.image.resize(input_mask, (128, 128))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "      input_image = tf.image.flip_left_right(input_image)\n",
    "      input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    \n",
    "    input_images.append(input_image)\n",
    "    input_masks.append(input_mask)\n",
    "      \n",
    "  input_images = tf.reshape(input_images, [-1, 128, 128, 3])\n",
    "  input_masks = tf.reshape(input_masks, [-1, 128, 128, 1])\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(files_name):\n",
    "    \n",
    "    input_images = [] \n",
    "    input_masks = []\n",
    "    for file_name in files_name:\n",
    "        input_image = tf.io.read_file(file_name)\n",
    "        input_image = tf.io.decode_jpeg(input_image, channels=3)\n",
    "        input_image = tf.image.resize(input_image, (128, 128))\n",
    "        \n",
    "        file_name = file_name[:-4] + '.png'\n",
    "        \n",
    "        if os.path.isfile(file_name) == False:\n",
    "            print(f'Not found mask file : {file_name}') \n",
    "            none_mask += 1\n",
    "            continue\n",
    "        \n",
    "        input_mask = tf.io.read_file(file_name)\n",
    "        input_mask = tf.io.decode_jpeg(input_mask, channels=3)\n",
    "        input_mask = tf.image.resize(input_mask, (128, 128))\n",
    "\n",
    "        input_image, input_mask = normalize(input_image, input_mask)\n",
    "        \n",
    "        input_images.append(input_image)\n",
    "        input_masks.append(input_mask)\n",
    "        \n",
    "    input_images = tf.reshape(input_images, [-1, 128, 128, 3])\n",
    "    input_masks = tf.reshape(input_masks, [-1, 128, 128, 1])\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:/Users/user/Desktop/datasets/Atopy Segmentation'\n",
    "paths = ['Intersect_0.75', 'Intersect_0.8', 'Intersect_0.85']\n",
    "grades = ['Grade0', 'Grade1', 'Grade2', 'Grade3']\n",
    "\n",
    "path = paths[2]\n",
    "grade = grades[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "x_test = {}\n",
    "y_test = {}\n",
    "\n",
    "x_extra = {}\n",
    "y_extra = {} \n",
    "\n",
    "\n",
    "# for path in paths:  \n",
    "# for grade in grades:\n",
    "x_train_list = glob(os.path.join(base_path, path, 'Atopy_Segment_Train', f'{grade}/*.jpg'))\n",
    "y_train_list = glob(os.path.join(base_path, path, 'Atopy_Segment_Train', f'{grade}/*.png'))\n",
    "\n",
    "x_test_list = glob(os.path.join(base_path, path, 'Atopy_Segment_Test', f'{grade}/*.jpg'))\n",
    "y_test_list = glob(os.path.join(base_path, path, 'Atopy_Segment_Test', f'{grade}/*.png'))\n",
    "\n",
    "x_extra_list = glob(os.path.join(base_path, path, 'Atopy_Segment_Extra', f'{grade}/*.jpg'))\n",
    "y_extra_list = glob(os.path.join(base_path, path, 'Atopy_Segment_Extra', f'{grade}/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "TRAIN_LENGTH = len(x_train_list) \n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_image_train(x_train_list)\n",
    "x_test, y_test = load_image_test(x_test_list)\n",
    "# x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected `trainable` argument to be a boolean, but got: efficient_net",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\workspace\\child_segmentation\\efficientnet_with_unet.ipynb 셀 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m UNet(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUnet-efficientNet\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=1'>2</a>\u001b[0m              width_coefficient\u001b[39m=\u001b[39;49m\u001b[39m1.6\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=2'>3</a>\u001b[0m              depth_coefficient\u001b[39m=\u001b[39;49m\u001b[39m2.2\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=3'>4</a>\u001b[0m              num_classes\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mbuild((\u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=7'>8</a>\u001b[0m train_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMean(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\workspace\\child_segmentation\\efficientnet_with_unet.ipynb 셀 16\u001b[0m in \u001b[0;36mUNet.__init__\u001b[1;34m(self, name, width_coefficient, depth_coefficient, num_classes)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=4'>5</a>\u001b[0m \u001b[39m# self.name = name \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=5'>6</a>\u001b[0m start_filters \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone \u001b[39m=\u001b[39m EfficientNet(width_coefficient\u001b[39m=\u001b[39;49mwidth_coefficient, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=7'>8</a>\u001b[0m                              depth_coefficient\u001b[39m=\u001b[39;49mdepth_coefficient)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle_conv \u001b[39m=\u001b[39m Conv2D(start_filters \u001b[39m*\u001b[39m \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=10'>11</a>\u001b[0m                             padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmiddle_conv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle_bn \u001b[39m=\u001b[39m BatchNormalization(axis\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmiddle_bn\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\workspace\\child_segmentation\\efficientnet_with_unet.ipynb 셀 16\u001b[0m in \u001b[0;36mEfficientNet.__init__\u001b[1;34m(self, width_coefficient, depth_coefficient, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, encoder_layers, layer_name, weights)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, width_coefficient, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=3'>4</a>\u001b[0m                 depth_coefficient, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=4'>5</a>\u001b[0m                 dropout_rate\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=10'>11</a>\u001b[0m                 layer_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mefficient_net\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=11'>12</a>\u001b[0m                 weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=12'>13</a>\u001b[0m   \u001b[39msuper\u001b[39;49m(EfficientNet, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(layer_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=13'>14</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_name \u001b[39m=\u001b[39m layer_name\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/efficientnet_with_unet.ipynb#ch0000015?line=14'>15</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_args \u001b[39m=\u001b[39m blocks_args\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:349\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39m# Mutable properties\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[39m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(trainable, \u001b[39mbool\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    347\u001b[0m         (\u001b[39misinstance\u001b[39m(trainable, (tf\u001b[39m.\u001b[39mTensor, tf\u001b[39m.\u001b[39mVariable)) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    348\u001b[0m          trainable\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m tf\u001b[39m.\u001b[39mbool)):\n\u001b[1;32m--> 349\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    350\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mExpected `trainable` argument to be a boolean, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    351\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbut got: \u001b[39m\u001b[39m{\u001b[39;00mtrainable\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    352\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainable \u001b[39m=\u001b[39m trainable\n\u001b[0;32m    353\u001b[0m \u001b[39m# A stateful layer is a layer whose updates are run during inference too,\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[39m# for instance stateful RNNs.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected `trainable` argument to be a boolean, but got: efficient_net"
     ]
    }
   ],
   "source": [
    "model = UNet(name='Unet-efficientNet', \n",
    "             width_coefficient=1.6, \n",
    "             depth_coefficient=2.2, \n",
    "             num_classes=3)\n",
    "\n",
    "model.build((1, 128, 128, 3))\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              train_loss=train_loss, \n",
    "              test_loss=test_loss,\n",
    "              metric = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "        create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_dataset,\n",
    "                          callbacks=[DisplayCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

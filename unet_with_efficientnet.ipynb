{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import constraints\n",
    "# from tensorflow.keras.utils import conv_utils\n",
    "# from tensorflow.keras.utils.data_utils import get_file\n",
    "# from keras.engine.topology import get_source_inputs\n",
    "# from keras.engine import InputSpec\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import multiply\n",
    "\n",
    "\n",
    "# from keras import optimizers\n",
    "# from keras.legacy import interfaces\n",
    "# from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "# from keras.engine.topology import Input\n",
    "# from keras.engine.training import Model\n",
    "# from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "# from keras.layers.core import Activation, SpatialDropout2D\n",
    "# from keras.layers.merge import concatenate\n",
    "# # from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.pooling import MaxPooling2D\n",
    "# from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "# from keras.regularizers import l2\n",
    "# from keras.layers.core import Dense, Lambda\n",
    "# from keras.layers.merge import concatenate, add\n",
    "# from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "# from keras.optimizers import SGD\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import Add, Concatenate\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# seed = 10\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "# os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapshotCallbackBuilder:\n",
    "    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n",
    "        self.T = nb_epochs\n",
    "        self.M = nb_snapshots\n",
    "        self.alpha_zero = init_lr\n",
    "\n",
    "    def get_callbacks(self, model_prefix='Model'):\n",
    "\n",
    "        callback_list = [\n",
    "            callbacks.ModelCheckpoint(\"./keras.model\",monitor='val_loss', \n",
    "                                   mode = 'min', save_best_only=True, verbose=1),\n",
    "            swa,\n",
    "            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n",
    "        ]\n",
    "\n",
    "        return callback_list\n",
    "\n",
    "    def _cosine_anneal_schedule(self, t):\n",
    "        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n",
    "        cos_inner /= self.T // self.M\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        return float(self.alpha_zero / 2 * cos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = LeakyReLU(alpha=0.1)(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    blockInput = BatchNormalization()(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from efficientnet import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "\n",
    "def UEfficientNet(input_shape=(None, None, 3),dropout_rate=0.1):\n",
    "\n",
    "    backbone = EfficientNetB4(weights='imagenet',\n",
    "                            include_top=False,\n",
    "                            input_shape=input_shape)\n",
    "    input = backbone.input\n",
    "    start_neurons = 16\n",
    "\n",
    "    conv4 = backbone.layers[342].output\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(dropout_rate)(pool4)\n",
    "    \n",
    "     # Middle\n",
    "    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = residual_block(convm,start_neurons * 32)\n",
    "    convm = LeakyReLU(alpha=0.1)(convm)\n",
    "    \n",
    "    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(dropout_rate)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
    "    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n",
    "    \n",
    "    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    conv3 = backbone.layers[154].output\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(dropout_rate)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
    "    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    conv2 = backbone.layers[92].output\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(0.1)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
    "    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n",
    "    \n",
    "    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    conv1 = backbone.layers[30].output\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(0.1)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
    "    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n",
    "    \n",
    "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n",
    "    uconv0 = Dropout(0.1)(uconv0)\n",
    "    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
    "    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n",
    "    \n",
    "    uconv0 = Dropout(dropout_rate/2)(uconv0)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n",
    "    \n",
    "    model = Model(input, output_layer)\n",
    "    model.name = 'u-xception'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 16, 16, 128), (None, 336)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\workspace\\child_segmentation\\unet_with_efficientnet.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=0'>1</a>\u001b[0m K\u001b[39m.\u001b[39mclear_session()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=1'>2</a>\u001b[0m img_size \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m UEfficientNet(input_shape\u001b[39m=\u001b[39;49m(img_size,img_size,\u001b[39m3\u001b[39;49m),dropout_rate\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m)\n",
      "\u001b[1;32mc:\\workspace\\child_segmentation\\unet_with_efficientnet.ipynb 셀 6\u001b[0m in \u001b[0;36mUEfficientNet\u001b[1;34m(input_shape, dropout_rate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=31'>32</a>\u001b[0m deconv3 \u001b[39m=\u001b[39m Conv2DTranspose(start_neurons \u001b[39m*\u001b[39m \u001b[39m8\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m)(uconv4)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=32'>33</a>\u001b[0m conv3 \u001b[39m=\u001b[39m backbone\u001b[39m.\u001b[39mlayers[\u001b[39m154\u001b[39m]\u001b[39m.\u001b[39moutput\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=33'>34</a>\u001b[0m uconv3 \u001b[39m=\u001b[39m concatenate([deconv3, conv3])    \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=34'>35</a>\u001b[0m uconv3 \u001b[39m=\u001b[39m Dropout(dropout_rate)(uconv3)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/workspace/child_segmentation/unet_with_efficientnet.ipynb#ch0000005?line=36'>37</a>\u001b[0m uconv3 \u001b[39m=\u001b[39m Conv2D(start_neurons \u001b[39m*\u001b[39m \u001b[39m8\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m)(uconv3)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\layers\\merge.py:968\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.layers.concatenate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcatenate\u001b[39m(inputs, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    938\u001b[0m   \u001b[39m\"\"\"Functional interface to the `Concatenate` layer.\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \n\u001b[0;32m    940\u001b[0m \u001b[39m  >>> x = np.arange(20).reshape(2, 2, 5)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39m      A tensor, the concatenation of the inputs alongside axis `axis`.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 968\u001b[0m   \u001b[39mreturn\u001b[39;00m Concatenate(axis\u001b[39m=\u001b[39;49maxis, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)(inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\layers\\merge.py:519\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    517\u001b[0m ranks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mlen\u001b[39m(shape) \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m shape_set)\n\u001b[0;32m    518\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ranks) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 519\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m    520\u001b[0m \u001b[39m# Get the only rank for the set.\u001b[39;00m\n\u001b[0;32m    521\u001b[0m (rank,) \u001b[39m=\u001b[39m ranks\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 16, 16, 128), (None, 336)]"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "img_size = 256\n",
    "model = UEfficientNet(input_shape=(img_size,img_size,3),dropout_rate=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
